---
title: "IQ measures"
output: html_notebook
---

Taken from M. Lee and E. J. Wagenmakers, Bayesian cognitive modeling (2013). 

In this example, we consider how to estimate the IQ of a set of people, each of whom have done multiple IQ tests. The data are the measures xij for the i = 1, ..., n people and their j = 1, ..., m repeated test scores.

We assume that the differences in repeated test scores are distributed as Gaussian error terms with zero mean and unknown precision. The mean of the Gaussian of a person's test scores corresponds to their latent true IQ. This will be different for each person. The standard deviation of the Gaussians corresponds to the accuracy of the testing instruments in measuring the one underlying IQ value. We assume this is the same for every person, since it is conceived as a property of the tests themselves.

Because we know quite a bit about the IQ scale, it makes sense to set priors for the mean and standard deviation using this knowledge. Our first attempt to set priors simply assume the actual IQ values are equally likely to be anywhere between 0 and 300, and standard deviations are anywhere between 0 and 100.


```{r, echo = F}
# clears workspace: 
rm(list=ls()) 
library(rstan)
library(bayesplot)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())


```


# Create some data

```{r}
x <- matrix(c(90, 95, 100, 105, 110, 115, 120, 125, 140, 150, 155, 160), 
      nrow=3, ncol=4, byrow=T) 

n <- nrow(x) # number of people
m <- ncol(x) # number of repeated measurements

data <- list(x=x, n=n, m=m) 

```


# Estimating the model

Call the stan function to estimate the model. 

```{r}
# parameters to be monitored: 
parameters <- c("mu", "sigma")

myfit <- stan(file='stan_models/IQ_measures.stan',   
                data=data, 
                pars=parameters,
                iter=2000, 
                chains=4, 
                thin = 1, 
                # warmup = 100,  # Stands for burn-in; Default = iter/2
                # seed = 123  # Setting seed; Default is random seed
                )

```


# Inspecting the results

```{r}
print(myfit)
plot(myfit)

# use bayesplot package
mcmc_areas(as.matrix(myfit), regex_pars = c("mu"), prob = 0.8)
mcmc_intervals(as.matrix(myfit), regex_pars = c("mu"), prob = 0.8, prob_outer = 0.95)

```


# Diagnostic plots: Traceplot
```{r}
traceplot(myfit, pars = parameters)
traceplot(myfit, pars = parameters, inc_warmup = T)

```

# Diagnostic plots: pairs plots

```{r}
pairs(myfit, pars = parameters)

```

# Getting the samples

```{r}

mu <- extract(myfit)$mu
sigma <- extract(myfit)$sigma 

```

# Exercises


- Change the priors for mu and sigma to more plausible ones and rerun the model. 

- What happens if you multiply the number of iterations by a factor of F and at the same time set the thinning to F?

- Plot the posterior distribution of the mean and the variance of the IQ of the three subjects. 

- Plot the posterior distribution of the difference in IQ (mu parameters) between the first two subjects. What is the probability that subject 1 has higher IQ than subject 2?

- Plot the posterior distribution of the absolute difference in IQ between the first two subjects. 