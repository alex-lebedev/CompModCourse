maxTrials <- max(Tsubj)
# Number of upper and lower boundary responses for each subject
Nu <- with(rawdata, aggregate(choice==2, by=list(y=subjID), FUN=sum)[["x"]])
Nl <- with(rawdata, aggregate(choice==1, by=list(y=subjID), FUN=sum)[["x"]])
# Minimum response time per subject
minRT <- with(rawdata, aggregate(RT, by=list(y=subjID), FUN=min)[["x"]])
# response times for upper and lower boundary responses
RTu <- array(0, c(numSubjs, max(Nu)) )
RTl <- array(0, c(numSubjs, max(Nl)) )
# Store each subjects' response time data
for (i in 1:numSubjs) {
curSubj         <- subjList[i]
tmp             <- subset(rawdata, rawdata$subjID == curSubj)
RTu[i, 1:Nu[i]] <- tmp$RT[tmp$choice==2] # (Nu/Nl[i]+1):Nu/Nl_max will be padded with 0's
RTl[i, 1:Nl[i]] <- tmp$RT[tmp$choice==1] # 0 padding is skipped in likelihood calculation
}
# List of data sent to Stan
dataList <- list(
N       = numSubjs, # Number of subjects
Nu_max  = max(Nu),  # Max (across subjects) number of upper boundary responses
Nl_max  = max(Nl),  # Max (across subjects) number of lower boundary responses
Nu      = Nu,       # Number of upper boundary responses for each subj
Nl      = Nl,       # Number of lower boundary responses for each subj
RTu     = RTu,      # upper boundary response times
RTl     = RTl,      # lower boundary response times
minRT   = minRT,    # minimum RT for each subject of the observed data
RTbound = RTbound   # lower bound or RT across all subjects (e.g., 0.1 second)
)
# This initialization will facilitate the sampling
inits_fixed <- c(0.5, 0.5, 0.5, 0.15)
genInitList = function(){
list(
mu_p     = c( log(inits_fixed[1]), qnorm(inits_fixed[2]), log(inits_fixed[3]), qnorm(inits_fixed[4]) ),
sigma    = c(1.0, 1.0, 1.0, 1.0),
alpha_pr = rep( log(inits_fixed[1]), numSubjs),
beta_pr  = rep( qnorm(inits_fixed[2]), numSubjs),
delta_pr = rep( log(inits_fixed[3]), numSubjs),
tau_pr   = rep( qnorm(inits_fixed[4]), numSubjs)
)
}
# Set sampler parameters
adapt_delta   = 0.95
stepsize      = 1
max_treedepth = 10
nchain        = 1
nthin         = 1
niter         = 3000
nwarmup       = 1000
nthin         = 1
# Estimation
myfit <- stan(file = "stan_models/choiceRT_ddm.stan",
data   = dataList,
pars   = parameters,
warmup = nwarmup,
init   = genInitList,
iter   = niter,
chains = nchain,
thin   = nthin,
control = list(adapt_delta   = adapt_delta,
max_treedepth = max_treedepth,
stepsize      = stepsize) )
# Load previous fit
# load('results/drift_diffusion3000.RData')
## Extract parameters
parVals <- extract(myfit, permuted=T)
alpha <- parVals$alpha
beta  <- parVals$beta
delta <- parVals$delta
tau   <- parVals$tau
# Individual parameters (e.g., individual posterior means)
allIndPars <- array(NA, c(numSubjs, numPars))
allIndPars <- as.data.frame(allIndPars)
for (i in 1:numSubjs) {
allIndPars[i, ] <- c( mean(alpha[, i]),
mean(beta[, i]),
mean(delta[, i]),
mean(tau[, i]))
}
allIndPars           <- cbind(allIndPars, subjList)
colnames(allIndPars) <- c("alpha",
"beta",
"delta",
"tau",
"subjID")
# Save the fit
# save(myfit, file = 'results/drift_diffusion3000.RData')
rm(list=ls())
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#definitions
data_file = 'data/choiceRT_exampleData.txt'
rawdata <- read.table( data_file, header = T, sep="\t")
# Individual Subjects
subjList <- unique(rawdata[,"subjID"])  # list of subjects x blocks
numSubjs <- length(subjList)  # number of subjects
# Specify the number of parameters and parameters of interest
numPars <- 4
parameters <- c("mu_alpha", "mu_beta", "mu_delta", "mu_tau",
"sigma",
"alpha", "beta", "delta", "tau",
"log_lik")
RTbound = 0.1
Tsubj <- as.vector( rep( 0, numSubjs ) ) # number of trials for each subject
for ( i in 1:numSubjs )  {
curSubj  <- subjList[i]
Tsubj[i] <- sum( rawdata$subjID == curSubj )  # Tsubj[N]
}
# Setting maxTrials
maxTrials <- max(Tsubj)
# Number of upper and lower boundary responses for each subject
Nu <- with(rawdata, aggregate(choice==2, by=list(y=subjID), FUN=sum)[["x"]])
Nl <- with(rawdata, aggregate(choice==1, by=list(y=subjID), FUN=sum)[["x"]])
# Minimum response time per subject
minRT <- with(rawdata, aggregate(RT, by=list(y=subjID), FUN=min)[["x"]])
# response times for upper and lower boundary responses
RTu <- array(0, c(numSubjs, max(Nu)) )
RTl <- array(0, c(numSubjs, max(Nl)) )
# Store each subjects' response time data
for (i in 1:numSubjs) {
curSubj         <- subjList[i]
tmp             <- subset(rawdata, rawdata$subjID == curSubj)
RTu[i, 1:Nu[i]] <- tmp$RT[tmp$choice==2] # (Nu/Nl[i]+1):Nu/Nl_max will be padded with 0's
RTl[i, 1:Nl[i]] <- tmp$RT[tmp$choice==1] # 0 padding is skipped in likelihood calculation
}
# List of data sent to Stan
dataList <- list(
N       = numSubjs, # Number of subjects
Nu_max  = max(Nu),  # Max (across subjects) number of upper boundary responses
Nl_max  = max(Nl),  # Max (across subjects) number of lower boundary responses
Nu      = Nu,       # Number of upper boundary responses for each subj
Nl      = Nl,       # Number of lower boundary responses for each subj
RTu     = RTu,      # upper boundary response times
RTl     = RTl,      # lower boundary response times
minRT   = minRT,    # minimum RT for each subject of the observed data
RTbound = RTbound   # lower bound or RT across all subjects (e.g., 0.1 second)
)
# This initialization will facilitate the sampling
inits_fixed <- c(0.5, 0.5, 0.5, 0.15)
genInitList = function(){
list(
mu_p     = c( log(inits_fixed[1]), qnorm(inits_fixed[2]), log(inits_fixed[3]), qnorm(inits_fixed[4]) ),
sigma    = c(1.0, 1.0, 1.0, 1.0),
alpha_pr = rep( log(inits_fixed[1]), numSubjs),
beta_pr  = rep( qnorm(inits_fixed[2]), numSubjs),
delta_pr = rep( log(inits_fixed[3]), numSubjs),
tau_pr   = rep( qnorm(inits_fixed[4]), numSubjs)
)
}
# Set sampler parameters
adapt_delta   = 0.95
stepsize      = 1
max_treedepth = 10
nchain        = 1
nthin         = 1
niter         = 3000
nwarmup       = 1000
nthin         = 1
# Estimation
myfit <- stan(file = "stan_models/choiceRT_ddm.stan",
data   = dataList,
pars   = parameters,
warmup = nwarmup,
init   = genInitList,
iter   = niter,
chains = nchain,
thin   = nthin,
control = list(adapt_delta   = adapt_delta,
max_treedepth = max_treedepth,
stepsize      = stepsize) )
myfit <- stan(file = "stan_models/choiceRT_ddm.stan",
data   = dataList,
#            pars   = parameters,
warmup = nwarmup,
init   = genInitList,
iter   = niter,
chains = nchain,
thin   = nthin,
control = list(adapt_delta   = adapt_delta,
max_treedepth = max_treedepth,
stepsize      = stepsize) )
rm(list=ls())
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#definitions
data_file = 'data/choiceRT_exampleData.txt'
rawdata <- read.table( data_file, header = T, sep="\t")
# Individual Subjects
subjList <- unique(rawdata[,"subjID"])  # list of subjects x blocks
numSubjs <- length(subjList)  # number of subjects
# Specify the number of parameters and parameters of interest
numPars <- 4
parameters <- c("mu_alpha", "mu_beta", "mu_delta", "mu_tau",
"sigma",
"alpha", "beta", "delta", "tau",
"log_lik")
RTbound = 0.1
Tsubj <- as.vector( rep( 0, numSubjs ) ) # number of trials for each subject
for ( i in 1:numSubjs )  {
curSubj  <- subjList[i]
Tsubj[i] <- sum( rawdata$subjID == curSubj )  # Tsubj[N]
}
# Setting maxTrials
maxTrials <- max(Tsubj)
# Number of upper and lower boundary responses for each subject
Nu <- with(rawdata, aggregate(choice==2, by=list(y=subjID), FUN=sum)[["x"]])
Nl <- with(rawdata, aggregate(choice==1, by=list(y=subjID), FUN=sum)[["x"]])
# Minimum response time per subject
minRT <- with(rawdata, aggregate(RT, by=list(y=subjID), FUN=min)[["x"]])
# response times for upper and lower boundary responses
RTu <- array(0, c(numSubjs, max(Nu)) )
RTl <- array(0, c(numSubjs, max(Nl)) )
# Store each subjects' response time data
for (i in 1:numSubjs) {
curSubj         <- subjList[i]
tmp             <- subset(rawdata, rawdata$subjID == curSubj)
RTu[i, 1:Nu[i]] <- tmp$RT[tmp$choice==2] # (Nu/Nl[i]+1):Nu/Nl_max will be padded with 0's
RTl[i, 1:Nl[i]] <- tmp$RT[tmp$choice==1] # 0 padding is skipped in likelihood calculation
}
# List of data sent to Stan
dataList <- list(
N       = numSubjs, # Number of subjects
Nu_max  = max(Nu),  # Max (across subjects) number of upper boundary responses
Nl_max  = max(Nl),  # Max (across subjects) number of lower boundary responses
Nu      = Nu,       # Number of upper boundary responses for each subj
Nl      = Nl,       # Number of lower boundary responses for each subj
RTu     = RTu,      # upper boundary response times
RTl     = RTl,      # lower boundary response times
minRT   = minRT,    # minimum RT for each subject of the observed data
RTbound = RTbound   # lower bound or RT across all subjects (e.g., 0.1 second)
)
# This initialization will facilitate the sampling
inits_fixed <- c(0.5, 0.5, 0.5, 0.15)
genInitList = function(){
list(
mu_p     = c( log(inits_fixed[1]), qnorm(inits_fixed[2]), log(inits_fixed[3]), qnorm(inits_fixed[4]) ),
sigma    = c(1.0, 1.0, 1.0, 1.0),
alpha_pr = rep( log(inits_fixed[1]), numSubjs),
beta_pr  = rep( qnorm(inits_fixed[2]), numSubjs),
delta_pr = rep( log(inits_fixed[3]), numSubjs),
tau_pr   = rep( qnorm(inits_fixed[4]), numSubjs)
)
}
# Set sampler parameters
adapt_delta   = 0.95
stepsize      = 1
max_treedepth = 10
nchain        = 1
nthin         = 1
niter         = 3000
nwarmup       = 1000
nthin         = 1
# Estimation
myfit <- stan(file = "stan_models/choiceRT_ddm.stan",
data   = dataList,
#            pars   = parameters,
warmup = nwarmup,
init   = genInitList,
iter   = niter,
chains = nchain,
thin   = nthin,
control = list(adapt_delta   = adapt_delta,
max_treedepth = max_treedepth,
stepsize      = stepsize) )
load('results/drift_diffusion3000.RData')
parVals <- extract(myfit, permuted=T)
head(parVals)
myfit
load('/Users/alebedev/GitHub/CompModCourse/Day3/Stan_tutorial_day3/results/drift_diffusion3000.RData')
head(parVals)
parVals <- extract(myfit, permuted=T)
parVals
head(parVals)
alpha <- parVals$alpha
beta  <- parVals$beta
delta <- parVals$delta
tau   <- parVals$tau
# Individual parameters (e.g., individual posterior means)
allIndPars <- array(NA, c(numSubjs, numPars))
allIndPars <- as.data.frame(allIndPars)
for (i in 1:numSubjs) {
allIndPars[i, ] <- c( mean(alpha[, i]),
mean(beta[, i]),
mean(delta[, i]),
mean(tau[, i]))
}
allIndPars           <- cbind(allIndPars, subjList)
colnames(allIndPars) <- c("alpha",
"beta",
"delta",
"tau",
"subjID")
final_d$cs <- as.factor(final_d$cs)
ggplot(final_d) + geom_point(aes(x = cs, y = gsr, color=cs), size = 1, data=final_d)+
theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
final_d$cs <- as.factor(final_d$cs)
ggplot(final_d) + geom_point(aes(x = cs, y = gsr, color=cs), size = 1, data=final_d)+
theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
library(R.matlab)
library(RSEIS)
library(xlsx)
library(ggplot2)
rdat <- readMat('/Users/alebedev/GitHub/CompModCourse/assignment/data/ildp2_pilot_gsr.mat')$rdat
endp <- which(rdat[,1]< c(mean(rdat[,1]) - 3*sd(rdat[,1])))[1]-500
rdat <- rdat[1:endp,]
gsr <- rdat[,1]
gsr_d <- detrend(gsr)
shock <- rdat[,3]
d <- as.data.frame(cbind(gsr, gsr_d,shock))
#ts.plot(d,gpars=list(yaxt='n', col=c(1:3)))
d$ms <- as.numeric(as.vector(row.names(d)))
# show data with two shock trials:
#ts.plot(d[c(16000*5):c(16000*9),2:3],gpars=list(yaxt='n', col=c(1:2)))
timing <- read.xlsx2('/Users/alebedev/GitHub/CompModCourse/assignment/data/pilot_TaskDesign.xlsx',1)
timing$trial <- as.numeric(as.vector(timing$trial))
timing$shockstart <- as.numeric(as.vector(timing$shockstart))
timing$shock <- as.numeric(as.vector(timing$shock))
timing_long <- data.frame(trial=rep(NA,max(timing$trial)*16000+16000))
timing_long$shock <- NA
for (i in 1:max(timing$trial)){
tmp <- subset(timing, timing$trial == i)
stamp <- (tmp$trial-1)*16000+1
timing_long$trial[stamp:c(stamp+16000)] <- i
if (tmp$shock==0.2){
timing_long$shock[c(stamp+tmp$shockstart*1000):c(stamp+tmp$shockstart*1000+200)] <- 1
}
}
timing_long <- timing_long[!is.na(timing_long$trial),]
timing_long$ms <- as.numeric(as.vector(row.names(timing_long)))
timing_long$shock[is.na(timing_long$shock)]<-0
# Check between CS+ timing (should be roughly 31.78 seconds):
(d$ms[which(d$shock>0)[185]]-d$ms[which(d$shock>0)[1]])/1000
(16*7+5.12)-(16*5+5.34)
(timing_long$ms[which(timing_long$shock>0)[202]]-timing_long$ms[which(timing_long$shock>0)[1]])/1000
# ms until the first electric shock (theory):
timing_long$ms[which(timing_long$shock>0)[1]]
# ms until the first electric shock (practice: actual gsr data):
d$ms[which(d$shock>0)[1]]
# Select based on timing model:
stamp1 <- d$ms[which(d$shock>0)[1]]-timing_long$ms[which(timing_long$shock>0)[1]]
d_sel <- d[stamp1:dim(d)[1],]
d_sel$ms <- as.numeric(c(1:dim(d_sel)[1]))
dd <- merge(d_sel, timing_long, by='ms')
dd$gsr_d<- dd$gsr_d-min(dd$gsr_d)
cor(dd$shock.x,dd$shock.y)
#ts.plot(cbind(dd$shock.x,dd$shock.y),gpars=list(col=c(1:2)))
final_df <- data.frame(trial=c(1:max(dd$trial)))
upperBound <- max(timing$shockstart)*2000 # defines upper boundary of the time-window
for (i in 1:max(dd$trial)){
tmp <- subset(dd, dd$trial == i)
final_df$gsr[i]<- max(tmp$gsr[2000:upperBound])-min(tmp$gsr[1:c(upperBound/2)])
final_df$gsr_d[i]<- max(tmp$gsr_d[2000:upperBound])-min(tmp$gsr_d[1:c(upperBound/2)])
}
# Plot individual trial responses:
i=41; tmp <- subset(dd, dd$trial == i); ts.plot(tmp$gsr)
final_d <- merge(final_df, timing, by='trial')
final_d$cs <- 0
final_d$cs[is.element(final_d$block,c('block1','block3')) & final_d$face=='stim/FaceA.JPG']<-1
final_d$cs[is.element(final_d$block,c('block2','block4')) & final_d$face=='stim/FaceB.JPG']<-1
t.test(final_d$gsr[final_d$cs==0],final_d$gsr[final_d$cs==1])
boxplot(final_d$gsr[final_d$cs==0],final_d$gsr[final_d$cs==1])
# Ploting responses per trial:
final_d$cs <- as.factor(final_d$cs)
ggplot(final_d) + geom_point(aes(x = cs, y = gsr, color=cs), size = 1, data=final_d)+
theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
rm(list=ls())
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#definitions
data_file = 'data/bandit2arm_exampleData.txt'
rawdata <- read.table( data_file, header = T, sep="\t")
# Individual Subjects
subjList <- unique(rawdata[,"subjID"])  # list of subjects x blocks
numSubjs <- length(subjList)  # number of subjects
# Specify the number of parameters and parameters of interest
numPars <- 2
parameters <- c("mu_A",
"mu_tau",
"sigma",
"A", "tau",
"log_lik")
Tsubj <- as.vector( rep( 0, numSubjs ) ) # number of trials for each subject
for ( i in 1:numSubjs )  {
curSubj  <- subjList[ i ]
Tsubj[i] <- sum( rawdata$subjID == curSubj )  # Tsubj[N]
}
# Setting maxTrials
maxTrials <- max(Tsubj)
choice  <- array(1, c(numSubjs, maxTrials) )
outcome <- array(0, c(numSubjs, maxTrials) )
for (i in 1:numSubjs) {
curSubj      <- subjList[i]
useTrials    <- Tsubj[i]
tmp          <- subset(rawdata, rawdata$subjID == curSubj)
choice[i, 1:useTrials] <- tmp$choice
outcome[i, 1:useTrials] <- tmp$outcome
}
dataList <- list(
N        = numSubjs,
T        = maxTrials,
Tsubj    = Tsubj,
choice   = choice,
outcome  = outcome,
numPars  = numPars
)
# Set sampler parameters
adapt_delta   = 0.95
stepsize      = 1
max_treedepth = 10
nchain        = 4
nthin         = 1
niter         = 3000
nwarmup       = 1000
nthin         = 1
# Estimation
myfit <- stan(file = "stan_models/bandit_2arm.stan",
data   = dataList,
pars   = parameters,
warmup = nwarmup,
#                  init   = genInitList,
iter   = niter,
chains = nchain,
thin   = nthin,
control = list(adapt_delta   = adapt_delta,
max_treedepth = max_treedepth,
stepsize      = stepsize) )
# load('results/bandit_2arm.RData')
## Extract parameters
parVals <- extract(myfit, permuted=T)
A   <- parVals$A
tau  <- parVals$tau
allIndPars <- array(NA, c(numSubjs, numPars))
allIndPars <- as.data.frame(allIndPars)
for (i in 1:numSubjs) {
allIndPars[i, ] <- c( mean(A[, i]),
mean(tau[, i]) )
}
allIndPars           <- cbind(allIndPars, subjList)
colnames(allIndPars) <- c("A",
"tau",
"subjID")
# Save the fit
# save(myfit, file = 'results/bandit_2arm.RData')
library(R.matlab)
library(RSEIS)
library(xlsx)
library(ggplot2)
rdat <- readMat('/Users/alebedev/GitHub/CompModCourse/assignment/data/ildp2_pilot_gsr.mat')$rdat
endp <- which(rdat[,1]< c(mean(rdat[,1]) - 3*sd(rdat[,1])))[1]-500
rdat <- rdat[1:endp,]
gsr <- rdat[,1]
gsr_d <- detrend(gsr)
shock <- rdat[,3]
d <- as.data.frame(cbind(gsr, gsr_d,shock))
#ts.plot(d,gpars=list(yaxt='n', col=c(1:3)))
d$ms <- as.numeric(as.vector(row.names(d)))
# show data with two shock trials:
#ts.plot(d[c(16000*5):c(16000*9),2:3],gpars=list(yaxt='n', col=c(1:2)))
timing <- read.xlsx2('/Users/alebedev/GitHub/CompModCourse/assignment/data/pilot_TaskDesign.xlsx',1)
timing$trial <- as.numeric(as.vector(timing$trial))
timing$shockstart <- as.numeric(as.vector(timing$shockstart))
timing$shock <- as.numeric(as.vector(timing$shock))
timing_long <- data.frame(trial=rep(NA,max(timing$trial)*16000+16000))
timing_long$shock <- NA
for (i in 1:max(timing$trial)){
tmp <- subset(timing, timing$trial == i)
stamp <- (tmp$trial-1)*16000+1
timing_long$trial[stamp:c(stamp+16000)] <- i
if (tmp$shock==0.2){
timing_long$shock[c(stamp+tmp$shockstart*1000):c(stamp+tmp$shockstart*1000+200)] <- 1
}
}
timing_long <- timing_long[!is.na(timing_long$trial),]
timing_long$ms <- as.numeric(as.vector(row.names(timing_long)))
timing_long$shock[is.na(timing_long$shock)]<-0
# Check between CS+ timing (should be roughly 31.78 seconds):
(d$ms[which(d$shock>0)[185]]-d$ms[which(d$shock>0)[1]])/1000
(16*7+5.12)-(16*5+5.34)
(timing_long$ms[which(timing_long$shock>0)[202]]-timing_long$ms[which(timing_long$shock>0)[1]])/1000
# ms until the first electric shock (theory):
timing_long$ms[which(timing_long$shock>0)[1]]
# ms until the first electric shock (practice: actual gsr data):
d$ms[which(d$shock>0)[1]]
# Select based on timing model:
stamp1 <- d$ms[which(d$shock>0)[1]]-timing_long$ms[which(timing_long$shock>0)[1]]
d_sel <- d[stamp1:dim(d)[1],]
d_sel$ms <- as.numeric(c(1:dim(d_sel)[1]))
dd <- merge(d_sel, timing_long, by='ms')
dd$gsr_d<- dd$gsr_d-min(dd$gsr_d)
cor(dd$shock.x,dd$shock.y)
#ts.plot(cbind(dd$shock.x,dd$shock.y),gpars=list(col=c(1:2)))
final_df <- data.frame(trial=c(1:max(dd$trial)))
upperBound <- max(timing$shockstart)*2000 # defines upper boundary of the time-window
for (i in 1:max(dd$trial)){
tmp <- subset(dd, dd$trial == i)
final_df$gsr[i]<- max(tmp$gsr[2000:upperBound])-min(tmp$gsr[1:c(upperBound/2)])
final_df$gsr_d[i]<- max(tmp$gsr_d[2000:upperBound])-min(tmp$gsr_d[1:c(upperBound/2)])
}
# Plot individual trial responses:
i=41; tmp <- subset(dd, dd$trial == i); ts.plot(tmp$gsr)
final_d <- merge(final_df, timing, by='trial')
final_d$cs <- 0
final_d$cs[is.element(final_d$block,c('block1','block3')) & final_d$face=='stim/FaceA.JPG']<-1
final_d$cs[is.element(final_d$block,c('block2','block4')) & final_d$face=='stim/FaceB.JPG']<-1
t.test(final_d$gsr[final_d$cs==0],final_d$gsr[final_d$cs==1])
boxplot(final_d$gsr[final_d$cs==0],final_d$gsr[final_d$cs==1])
# Ploting responses per trial:
final_d$cs <- as.factor(final_d$cs)
ggplot(final_d) + geom_point(aes(x = cs, y = gsr, color=cs), size = 1, data=final_d)+
theme_bw()+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
